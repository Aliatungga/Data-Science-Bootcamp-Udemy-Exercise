# -*- coding: utf-8 -*-
"""Logistic Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NSwcNFPqzPeHg2C8MtaIY0dHKNZ0noDu
"""

import pandas as pd
import numpy as np

data_preprocessed = pd.read_csv('Absenteeism_preprocessed.csv')

"""# Logistic Regression

## Targets
"""

data_preprocessed['Absenteeism Time in Hours'].median()

targets = np.where(data_preprocessed['Absenteeism Time in Hours'] >
                   data_preprocessed['Absenteeism Time in Hours'].median(),1,0)
targets

data_preprocessed['Excessive Absenteeism'] = targets
data_preprocessed.head()

"""## A comment on the targets"""

targets.sum() / targets.shape[0]

data_with_targets = data_preprocessed.drop(['Absenteeism Time in Hours'],axis=1)

data_with_targets is data_preprocessed

data_with_targets.head()

"""## Select the inputs for the regression"""

data_with_targets.shape

data_with_targets.iloc[:,:14]

data_with_targets.iloc[:,:-1]

unscaled_inputs = data_with_targets.iloc[:,:-1]

"""## Standardize the data"""

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import StandardScaler

class CustomScaler(BaseEstimator, TransformerMixin):

    def __init__(self,columns,copy=True,with_mean=True,with_std=True):
      self.scaler = StandardScaler(copy,with_mean,with_std)
      self.columns = columns
      self.mean = None
      self.var_ = None

    def fit(self,x,y=None) :
      self.scaler.fit(x[self.columns],y)
      self.mean_ = np.mean(X[self.columns])
      self.var_ = np.var(x[self.columns])
      return self

    def transform(self, x, y=None, copy=None):
      init_col_order = x.columns
      x_scaled = pd.DataFrame(self.scaler.transform(x[self.columns]), columns=self.columns)
      x_not_scaled = x.loc[:,~x.columns.isin(self.columns)]
      return pd.concat([x_not_scaled, x_scaled], axis=1)[init_col_order]

unscaled_inputs.columns.values

columns_to_scale = ['Month Value','Day of the Week', 'Transportation Expense', 'Distance to Work',
       'Age', 'Daily Work Load Average', 'Body Mass Index','Children', 'Pet']

absenteeism_scaler.fit(unscaled_inputs)

scaled_Inputs = absenteeism_scaler.transform(unscaled_inputs)
scaled_Inputs

scaled_Inputs.shape

"""# Split the data into train & test and shuffle"""

from sklearn.model_selection import train_test_split

"""## split"""

train_test_split(scaled_Inputs,targets)

x_train, x_test, y_train, y_test = train_test_split(scaled_Inputs, targets)

print (x_train.shape, y_train.shape)

print (x_test.shape, y_test.shape)

x_train, x_test, y_train, y_test = train_test_split(scaled_Inputs, targets, train_size=0.8, random_state=20)

print (x_train.shape, y_train.shape)

print (x_test.shape, y_test.shape)

"""# logistic regresion with sklearn"""

from sklearn.linear_model import LogisticRegression
from sklearn import metrics

"""## training the model"""

reg = LogisticRegression()

reg.fit(x_train, y_train)

reg.score(x_train, y_train)

"""## manually check the accuracy"""

model_outputs = reg.predict(x_train)
model_outputs

y_train

model_outputs == y_train

np.sum(model_outputs==y_train)

model_outputs.shape[0]

np.sum(model_outputs==y_train) / model_outputs.shape[0]

"""## finding the intercept and coefficients"""

reg.intercept_

reg.coef_

unscaled_inputs.columns.values

feature_name = unscaled_inputs.columns.values

summary_table = pd.DataFrame (columns=['Feature name'], data=feature_name)
summary_table['Coefficient'] = np.transpose(reg.coef_)
summary_table

summary_table.index = summary_table.index + 1
summary_table.loc[0] = ['Intercept', reg.intercept_[0]]
summary_table = summary_table.sort_index()
summary_table

"""## Interpreting with coefficients"""

summary_table['Odds_ratio'] = np.exp(summary_table.Coefficient)
summary_table

summary_table.sort_values('Odds_ratio', ascending=False)

"""# Testing the model"""

reg.score(x_test, y_test)

predicted_proba = reg.predict_proba(x_test)
predicted_proba

predicted_proba.shape

predicted_proba[:,1]